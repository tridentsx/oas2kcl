# global:
#  pullSecret:
#  registry:
#    url: armdocker.rnd.ericsson.se
#    pullSecret: # deprecated
#    imagePullPolicy:
#    repoPath:
#  adpBR:
#    broServiceName: eric-ctrl-bro
#    broGrpcServicePort: 3000
#    brLabelKey: adpbrlabelkey
#  timezone: UTC
  ## add for DR113
  #security:
  #  tls:
  #    enabled: true
  ## added for DR-D1123-124
  #  policyBinding:
  #    create: true
  #  policyReferenceMap:
  #    default-restricted-security-policy: customer-z-restricted
  #    erole-f003d240cca24da741: customer-z-network
  ## added for DR-D1123-134
  # securityPolicy:
  #   rolekind:  
  #internalIPFamily: IPv6 or IPv4
  # fsGroup:
  #   manual:
  #   namespace:
  #nodeSelector: {}
#   networkPolicy:
#     enabled: false
  # hooklauncher:
  #   executor: service
  ## add for dr DR-D470222-010
  #log:
  #  streamingMethod: indirect,direct or dual
  # podSecurityContext:
  #    supplementalGroups: [22, 33, 444]
  # logShipper:
  #   deployment:
  #     model: "" # supported value: static, ""
  #   config:
  #     image:
  #       registry:
  #       repoPath:
  # imageCredentials:
  #   logshipper:
  #     registry:
  #       url:
  #     repoPath:

brAgent:
  enabled: false
  logLevel: "info"
  RootLogLevel: "info"
  PGAgentLogLevel: "info"
  ## logicalDBBackupEnable control the behavior of backup and restore.
  ## if true, PG will take single database backup and restore.
  ## if false, PG will take whole service DB backup and restore.
  ##
  logicalDBBackupEnable: false
  ## the value of backupTypelist is one list that used to define the scopes of service, and bra use them to register in the BRO.
  ## current DDB PG only support one DDB instance. Then the backupTypelist only allow set one value or empty string as default scope.
  ## for example.
  ## backupTypeList:
  ##  - "configuration-data"
  backupTypeList: [ ]

  properties:
    production_date:
  ## By default, brLabelValue is the Chart.Name which is unique
  brLabelValue:
##   For backupTypeList only declares a single value, backup and restore action need more parameters which will
  ## be defined in the configmap.
  ## The parameter backupDataModelConfig specify the name of external configmap.
  ## Notes: the configmap resource must create before BRA deployment.
  ## For detail, refer the doc Document Database PG Service Deployment Guide.
  ##
  #backupDataModelConfig:

## Name used to override the service name
# nameOverride:

## postgres image repository
imageCredentials:
  logshipper:
    registry:
      imagePullPolicy:
  hooklauncher:
    registry:
      url:
      imagePullPolicy:
    repoPath:
  pg13:
    repoPath:
  metrics:
    repoPath:
  kubeclient:
    repoPath:
  brm13:
    repoPath:
  bra:
    repoPath:
  feoperator:
    repoPath:
  beoperator:
    repoPath:

  pullSecret:
  repoPath:
#   Specify a imagePullPolicy
  ## 'Always' if imageTag is 'latest', else set to 'IfNotPresent'
  ##
  #  pullPolicy: IfNotPresent # deprecated

  registry:
    ## Specify imagePullSecrets
    ##
    url:
#    pullSecret: # deprecated
    imagePullPolicy:


highAvailability:
  synchronousModeEnabled: true
  replicaCount: 2

# DR-D1120-056-AD - Con use only one minAvailable or maxUnavailable, not both
# Using only when highAvailability.replicaCount > 1
podDisruptionBudget:
  # String minAvailable or maxUnavailable { range="1..max | 0%..100% , null }, one of them must be empty or null
  minAvailable:

## Create a database
## Default: the postgres user
#postgresDatabase:


## Postgres' user credentials stored as Kubernetes Secrets
credentials:
  kubernetesSecretName:
  keyForUserId: custom-user
  keyForUserPw: custom-pwd
  keyForSuperPw: super-pwd
  keyForMetricsPw: metrics-pwd
  keyForReplicaId: replica-user
  keyForReplicaPw: replica-pwd

## Specify initdb arguments, e.g. --data-checksums

postgresInitdbArgs:
  - auth-host: md5
  - auth-local: trust
  - encoding: UTF8
  - locale: en_US.UTF-8
  - data-checksums

## Use an alternate scheduler, e.g. "stork".
##
# schedulerName:

## Specify runtime config parameters as a dict, using camelCase, e.g.
## shared_buffers: "500MB"
## log_connections: "yes"
## huge_pages: "off"
#postgresConfig:
#  shared_buffers: "500MB"
#  log_connections: "yes"
#  huge_pages: "off"

postgresLogging:
  ## Specify if enable postgres logging, true or false
  enabled: false

#User information for metrics
#metricsDefPwd:

## Using RollingUpdate, specify the update strategy for statefulset
updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    partition: 0

persistentVolumeClaim:
  enabled: true

  ## database data Persistent Volume Storage Class
  ## If defined in helm installation, persistentVolumeClaim volume will use defined value as storageClassName to create pvc.
  ## if not defined, it will use the default storage class on the kubernetes cluster.
#  storageClassName: ""
  size: 8Gi
  housekeeping_threshold: 100

## If enabled, a tmpfs of <size> will be mounted to /dev/shm
## This overrides the default shared memory device at /dev/shm & allows shared memory to be resized over the 64MB limit in k8s
sharedMemory:
  enabled: false
  size: 128Mi

restore:
  # The path stores the backup data which will be restored
  backupDataDir: ""

patroni:
  # default is INFO
  logLevel: INFO
  requests_logLevel: INFO



metrics:
  enabled: true
  datasource: ""
  autoDiscoverDatabases: false
  logLevel: info
  service:
    port: 9187
    #nodePort:
  hostname: eric-pm-server
  queryMetrics:
    pg_postmaster:
      master: true
      #includeDatabases: ["postgres"]
      query: "SELECT pg_postmaster_start_time as start_time_seconds from pg_postmaster_start_time()"
      metrics:
        - start_time_seconds:
            usage: "GAUGE"
            description: "Time at which postmaster started"

## Configure resource requests and limits
##
resources:
  logshipper:
    requests:
      memory: "50Mi"
      cpu: "50m"
      ephemeral-storage: "320Mi"
    limits:
      memory: "100Mi"
      cpu: "100m"
      ephemeral-storage: "320Mi"
  postgres:
    requests:
      memory: "256Mi"
      cpu: "100m"
      hugepages-2Mi: # This value only work when hugepage is properly configured. As a requirement of Kubernetes, requests and limits must be the same.
      hugepages-1Gi: # This value only work when hugepage is properly configured. As a requirement of Kubernetes, requests and limits must be the same.
      ephemeral-storage: "10Gi"
    limits:
      cpu: "1"
      memory: "2560Mi"
      hugepages-2Mi: # This value only work when hugepage is properly configured. As a requirement of Kubernetes, requests and limits must be the same.
      hugepages-1Gi: # This value only work when hugepage is properly configured. As a requirement of Kubernetes, requests and limits must be the same.
      ephemeral-storage: "12Gi"

  metrics:
    requests:
      memory: "128Mi"
      cpu: "100m"
      ephemeral-storage: "300Mi"
    limits:
      cpu: "200m"
      memory: "256Mi"
      ephemeral-storage: "320Mi"
  kube_client:
    requests:
      memory: "256Mi"
      cpu: "100m"
      ephemeral-storage: "300Mi"
    limits:
      cpu: "200m"
      memory: "512Mi"
      ephemeral-storage: "320Mi"
  brm:
    requests:
      memory: "256Mi"
      cpu: "300m"
      ephemeral-storage: "300Mi"
    limits:
      cpu: "1"
      memory: "512Mi"
      ephemeral-storage: "320Mi"
  bra:
    requests:
      memory: "1Gi"
      cpu: "500m"
      ephemeral-storage: "10Gi"
    limits:
      cpu: "1"
      memory: "2Gi"
      ephemeral-storage: "12Gi"
    jvm:
      # Comply with DR DR-D1126-011
      initialMemoryAllocationPercentage: 50 # default: 50
      smallMemoryAllocationMaxPercentage: 70 # default: 70
      largeMemoryAllocationMaxPercentage: 50 # default: 50
  hooklauncher:
    requests:
      memory: "50Mi"
      cpu: "50m"
      ephemeral-storage: "300Mi"
    limits:
      memory: "100Mi"
      cpu: "100m"
      ephemeral-storage: "320Mi"
  feoperator:
    requests:
      memory: "250Mi"
      cpu: "100m"
      ephemeral-storage: "350Mi"
    limits:
      cpu: "500m"
      memory: "500Mi"
      ephemeral-storage: "400Mi"
  beoperator:
    requests:
      memory: "250Mi"
      cpu: "100m"
      ephemeral-storage: "350Mi"
    limits:
      cpu: "500m"
      memory: "500Mi"
      ephemeral-storage: "400Mi"

service:
  port: 5432
  # nodePort:
  ## add for DR113
  endpoints:
    postgres:
      tls:
        enforced: required
    postgresExporter:
      tls:
        enforced: required

hooks:
  pre_install:
    activeDeadlineSeconds: 300

nodeSelector:
  postgres: { }
  brAgent: { }
  cleanuphook: { }
  hooklauncher: { }
  feoperator: { }
  oppatchhook: { }
  beoperator: { }

terminationGracePeriodSeconds:
  postgres: 30
  brAgent: 30
  feoperator: 30
  beoperator: 30

## Interface for setting Node labels and tolerations for pod assignment
tolerations:
  postgres: [ ]
  brAgent:
    - key: node.kubernetes.io/not-ready
      operator: Exists
      effect: NoExecute
      tolerationSeconds: 0
    - key: node.kubernetes.io/unreachable
      operator: Exists
      effect: NoExecute
      tolerationSeconds: 0
  cleanuphook:
    - key: node.kubernetes.io/not-ready
      operator: Exists
      effect: NoExecute
      tolerationSeconds: 0
    - key: node.kubernetes.io/unreachable
      operator: Exists
      effect: NoExecute
      tolerationSeconds: 0
  hooklauncher:
    - key: node.kubernetes.io/not-ready
      operator: Exists
      effect: NoExecute
      tolerationSeconds: 0
    - key: node.kubernetes.io/unreachable
      operator: Exists
      effect: NoExecute
      tolerationSeconds: 0
  feoperator:
    - key: node.kubernetes.io/not-ready
      operator: Exists
      effect: NoExecute
      tolerationSeconds: 0
    - key: node.kubernetes.io/unreachable
      operator: Exists
      effect: NoExecute
      tolerationSeconds: 0
  oppatchhook:
    - key: node.kubernetes.io/not-ready
      operator: Exists
      effect: NoExecute
      tolerationSeconds: 0
    - key: node.kubernetes.io/unreachable
      operator: Exists
      effect: NoExecute
      tolerationSeconds: 0
  beoperator:
    - key: node.kubernetes.io/not-ready
      operator: Exists
      effect: NoExecute
      tolerationSeconds: 0
    - key: node.kubernetes.io/unreachable
      operator: Exists
      effect: NoExecute
      tolerationSeconds: 0
# Note: According to design rule for adp, the following toleration will be added to brAgent and cleanuphook, and the configuration for
# the these tolerations will be ignored.
#tolerations:
#  postgres:
#    - key: node.kubernetes.io/not-ready
#      operator: Exists
#      effect: NoExecute
#      tolerationSeconds: 0
#    - key: node.kubernetes.io/unreachable
#      operator: Exists
#      effect: NoExecute
#      tolerationSeconds: 0


## affinity.podAntiAffinity , valid value are "soft" or "hard".
affinity:
  podAntiAffinity: soft
  topologyKey: "kubernetes.io/hostname"

##productinfo
productinfo:
  rstate: R7A

## Kubernetes cluster info
## Note: VERY IMPORTANT, DO NOT CHANGE THE FOLLOWING CONFIGURATION, THEY ARE VERY SENSITIVE INFORMATION ABOUT KUBERNETES CLUSTER
## IF YOU REALLY WANT TO CHANGE , PLEASE ASK YOUR KUBERNETES ADMINISTRATOR.
k8sClusterInfo:
  clusterDomain: cluster.local

#liveness probe and readiness probe
probes:
  logshipper:
    livenessProbe:
      initialDelaySeconds: 1
      timeoutSeconds: 10
      periodSeconds: 10
      failureThreshold: 30
  postgres:
    startupProbe:
      initialDelaySeconds: 0
      periodSeconds: 5
      failureThreshold: 70
      timeoutSeconds: 25
    livenessProbe:
      initialDelaySeconds: 0
      periodSeconds: 15
      failureThreshold: 10
      timeoutSeconds: 15
    readinessProbe:
      initialDelaySeconds: 0
      periodSeconds: 10
      timeoutSeconds: 10
      failureThreshold: 6
      successThreshold: 1
  metrics:
    startupProbe:
      initialDelaySeconds: 0
      periodSeconds: 5
      failureThreshold: 70
      timeoutSeconds: 5
    livenessProbe:
      initialDelaySeconds: 0
      periodSeconds: 10
      failureThreshold: 20
      timeoutSeconds: 10
  brm:
    startupProbe:
      initialDelaySeconds: 0
      periodSeconds: 10
      failureThreshold: 50
      timeoutSeconds: 10
    livenessProbe:
      initialDelaySeconds: 0
      periodSeconds: 5
      failureThreshold: 40
      timeoutSeconds: 5
    readinessProbe:
      initialDelaySeconds: 0
      periodSeconds: 5
      timeoutSeconds: 5
      failureThreshold: 10
      successThreshold: 1
  bra:
    startupProbe:
      initialDelaySeconds: 0
      periodSeconds: 5
      failureThreshold: 70
      timeoutSeconds: 5
    livenessProbe:
      initialDelaySeconds: 0
      periodSeconds: 5
      failureThreshold: 40
      timeoutSeconds: 5
    readinessProbe:
      initialDelaySeconds: 0
      periodSeconds: 5
      timeoutSeconds: 5
      failureThreshold: 6
      successThreshold: 1
  feoperator:
    startupProbe:
      initialDelaySeconds: 0
      periodSeconds: 5
      failureThreshold: 50
      timeoutSeconds: 5
    livenessProbe:
      initialDelaySeconds: 0
      periodSeconds: 15
      failureThreshold: 15
      timeoutSeconds: 15
    readinessProbe:
      initialDelaySeconds: 0
      periodSeconds: 15
      timeoutSeconds: 15
      failureThreshold: 5
      successThreshold: 1
  beoperator:
    startupProbe:
      initialDelaySeconds: 0
      periodSeconds: 5
      failureThreshold: 50
      timeoutSeconds: 5
    livenessProbe:
      initialDelaySeconds: 0
      periodSeconds: 15
      failureThreshold: 15
      timeoutSeconds: 15
    readinessProbe:
      initialDelaySeconds: 0
      periodSeconds: 15
      timeoutSeconds: 15
      failureThreshold: 5
      successThreshold: 1

log:
  # Supported values ["stdout", "stream"]
  outputs:
    - stdout
  # Comply with DR DR-D470222-010 set to default local streamingMethod
  # Can be one of the following:
  # direct: Direct streaming to the Log Aggregator (Log Transformer).
  # indirect: Stdout to infrastructure logging framework.
  # dual: Stdout to infrastructure logging framework and direct streaming to Log Aggregator.
  # null: for null or absent parameter the streaming method is determined by global.log.streamingMethod.
  streamingMethod: ""
  # The following options are supported: "none", "adp".
  # Default: "none"
  schema: "none"

logShipper:
  logLevel: info
  storage:
    path: "/logs"
    medium: "Ephemeral" # Memory or Ephemeral
    size: "500Mi"
  output:
    logTransformer:
      host: "eric-log-transformer"

securityContext:
  allowPrivilegeEscalation: false

securityPolicy:
  postgres:
    rolename: eric-data-document-database-pg
  feoperator:
    rolename: eric-data-document-database-pg
  beoperator:
    rolename: eric-data-document-database-pg
  dispatchjob:
    rolename: eric-data-document-database-pg
  pgdatahook:
    rolename: eric-data-document-database-pg
  pghook:
    rolename: eric-data-document-database-pg
  oppatchhook:
    rolename: eric-data-document-database-pg
  preuphook:
    rolename: eric-data-document-database-pg
  prerohook:
    rolename: eric-data-document-database-pg
  postdelhook:
    rolename: eric-data-document-database-pg
  hooklauncher:
    rolename: eric-lcm-smart-helm-hooks

# Note: According to design rule DR-D1120-090-AD for adp,
#       the follow topologySpreadConstraints will be added to postgres POD.
topologySpreadConstraints:
  postgres: [ ]

# Pod priority configuration aligned to DR-D1120-110-AD
podPriority:
  postgres:
    priorityClassName: "" # No priority set
  brAgent:
    priorityClassName: ""
  cleanuphook:
    priorityClassName: ""
  hooklauncher:
    priorityClassName: ""
  feoperator:
    priorityClassName: ""
  beoperator:
    priorityClassName: ""

# Pod bandwidth limit comply with DR-D1125-040-AD
bandwidth:
  postgres:
    maxEgressRate: ""
  brAgent:
    maxEgressRate: ""
  cleanuphook:
    maxEgressRate: ""
  # Deprecate this parameter for ADPPRG-132599
  #hooklauncher:
  #  maxEgressRate:
  feoperator:
    maxEgressRate: ""
  beoperator:
    maxEgressRate: ""

labels: { }
annotations: { }

networkPolicy:
  enabled: true
  matchLabels: [ ]

hooklauncher:
  cleanup: onSuccess # 3 possible values: true, false, onSuccess
  terminateEarlyOnFailure: true
  backoffLimit: 2

appArmorProfile:
  type:
  localhostProfile:
  postgres:
    type:
    localhostProfile:
  metrics:
    type:
    localhostProfile:
  kube_client:
    type:
    localhostProfile:
  brm:
    type:
    localhostProfile:
  bra:
    type:
    localhostProfile:
  hooklauncher:
    type:
    localhostProfile:
  feoperator:
    type:
    localhostProfile:
  beoperator:
    type:
    localhostProfile:


seccompProfile:
  type: ""
  localhostProfile: ""
  postgres:
    type: ""
    localhostProfile: ""
  metrics:
    type: ""
    localhostProfile: ""
  kube_client:
    type: ""
    localhostProfile: ""
  brm:
    type: ""
    localhostProfile: ""
  bra:
    type: ""
    localhostProfile: ""
  hooklauncher:
    type: ""
    localhostProfile: ""
  feoperator:
    type: ""
    localhostProfile: ""
  beoperator:
    type: ""
    localhostProfile: ""

operator:
  operandConfig:
    hugepages_2Mi:
    hugepages_1Gi:
    ephemeral_storage_base: 80Mi

shhRbacEnabled: true

enableNewScrapePattern: false
